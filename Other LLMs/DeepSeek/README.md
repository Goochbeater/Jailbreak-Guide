# DeepSeek

## Model Information
- **Latest Versions**:
  - DeepSeek-R1-0528 (671B parameters, 37B activated)
  - DeepSeek-R1-0528-Qwen3-8B (distilled 8B model)
  - DeepSeek V3.1 (hybrid thinking/non-thinking)
  - DeepSeek V3.2
- **Access**: https://chat.deepseek.com/
- **Cost**: Free via OpenRouter, pennies on API
- **Censorship**: 1/10 with jailbreak, 9/10 without (Gemini-style external filter)
- **Intelligence**: 8/10 (reasoning model, approaches O3/Gemini 2.5 Pro)
- **Context**: 128K tokens (V3.1), 256K (some variants)
- **License**: MIT

## Features
- R1-0528 shows major improvements: AIME 2025 accuracy jumped from 70% to 87.5%
- Hybrid mode in V3.1: can switch between thinking and non-thinking modes
- Open-source with full commercial use allowed
- Comparable performance to OpenAI o1 on math, code, and reasoning
- Native support for system prompts in latest version

## POE Alternatives
- DeepSeek V3.1: [https://poe.com/852x-DeepSeek](https://poe.com/852x-DeepSeek)
- DeepSeek R1-FW: [https://poe.com/851x-DeepSeek](https://poe.com/851x-DeepSeek)
